[["index.html", "Py-Book Preface Setup", " Py-Book Preface .github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}} This is a book aimed at summarizing my knowledge in python language Setup I mainly work with RStudio, therefore I won‚Äôt go deeper inside the usual Pyhton Setup, instead I just suggest to install the package reticulate and work with it within RStudio. #install.packages(&#39;reticulate&#39;) library(reticulate) # conda_list() # conda_version() virtualenv_create(envname = &quot;r-reticulate&quot;, packages = c(&#39;pandas&#39;, &#39;numpy&#39;, &#39;scikit-learn&#39;) ) virtualenv_list() virtualenv_exists() virtualenv_root() #------------------------------------- use_virtualenv(virtualenv_root() ) #repl_python() #quit Now Python is ready to use Here you can find everything you need to know on using reticulate package in r To clear all the environment # import sys # sys.modules[__name__].__dict__.clear() #Or delete single object #del &lt;variable_name&gt; "],["algorithms.html", "Chapter 1 Algorithms 1.1 Definitions 1.2 Computers Architecture", " Chapter 1 Algorithms 1.1 Definitions Algorithm is a non-ambiguous and repeatable sequence of instructions which allows to solve a problem in a general way. The instructions are as et of elementary operations which are assumed to be executable by a predefined executor. Where: Executor model a schematic description of internal architecture of the executor and its components Some components are numerical variables and expressions, assignment, conditionals, for loops, while loops, function definition and invocation. Expressions are constructed with parentheses, constants, scalar variables, arithmetic or logical operators, and follow the formation rules of arithmetic and logical expressions. We assume a countable set of symbols, called variables. A variable may be: undefined, that is, have no value, or scalar, that is,have a numerical or logical value, or vector, that is, have a finite sequence of values Every scalar variable in the expression is replaced by its value and all operations in the resulting expression are computed in the order set by the rules of arithmetic and logic, until the value of the expression is obtained. An assignment is a pair consisting of a scalar variable and an expression, separated by an assignment symbol. A conditional statement is an expression, which evaluates to either true or false,and two sequences of instructions. A for loop consists of a scalar variableùë•, a vector variableùë£, and a sequence of instructions. A while loop is an expression, which evaluates to either true or false, and asequence of instructions A function definition is a function name, a sequence of parameters, and a sequence of instructions, called the body of the function. A function invocation is a function name and a sequence of expressions. Set of operations the machine can execute and how the components interact to compute them Set of rules to write algorithms that use the machine operations, i.e., a language. 1.2 Computers Architecture Independent of the writing style, the recommended format for algorithm presentation consists of an Input section describing a generic instance, an Output section describing the corresponding solution, an Algorithm section listing the lines of code in the chosen style. The sequences of instructions in conditional statements, for and while loops must be indented. The Von Neumann architecture: a single memory stores both program and data. A central processing unit (CPU) executes program instructions. Arithmetic operations are computed by a sub-unit of the CPU, the arithmetic-logic unit (ALU). The CPU contains a small amount of memory in a collection of registers,which store the current instruction (instruction register, IR), the address in memory of the next instruction (program counter, PC), operands, memory addresses, and the status of the last executed instruction. A bidirectional bus connects the CPU to the memory. Input and output units are connected to the memory. "],["basics.html", "Chapter 2 Basics 2.1 Control Flow 2.2 Collection Types", " Chapter 2 Basics 2.1 Control Flow 2.1.1 Data Types int() converts to integers str() converts to strings float() converts to float (integers with decimals) There exist also booleans: True, False So what are the other comparison operators? Well, we‚Äôve got: equal to ==, not equal to !=, greater than &gt;, smaller than &lt;, greater or equal to &gt;=, smaller or equal to &lt;= Other booleans operators are and, or, not. Be careful not to confuse assignment (one equals sign) with comparison (two equals signs) 2.1.2 Variables A variable lets you store a value by assigning it to a name. The name can be used to refer to the value later in the program. You can use letters, numbers, and underscores in variable names. But you can‚Äôt use special symbols, or start the name with a number. x = 5 name = &quot;Alessio&quot; print(x,name) #&gt; 5 Alessio The input function prompts the user for input, and returns what they enter as a string. Like this: x = int(input(&quot;Insert a value for x:&quot;)) Remember to specify the type of the value in this case int was used in order to work with an integer value for x #### In-Place Operators In-place operators let you write code like `x = x + 3¬¥ more concisely, as ‚Äòx += 3‚Äô, for all the operations &lt;+,-,*,/,%,**,//&gt; 2.1.3 Logics 2.1.3.1 if, else, elif ifstatements to run code based on a certain condition The else statement can be used to run some statements when the condition of the if statement is not met. elif is the short for else if statement, used when chaining several if statements if condition: statement elif condition: statement: else condition: statement Python uses indentation (that empty space at the beginning of a line) to delimit blocks of code. Depending on the program‚Äôs logic, indentation can be mandatory. As you can see, the statements in the if should be indented. 2.1.3.2 while We can use the while loop to repeat a block of code multiple times. For example, let‚Äôs say we need to process multiple user inputs, so that each time the user inputs something, the same block of code needs to execute. To end a while loop prematurely, we can use a break statement. Instead continue jumps back to the top of the loop, rather than stopping it. Basically, the continue statement stops the current iteration and continues with the next one. 2.1.4 Iteration The for loop is used to iterate over a given sequence, such as lists or strings. string = &quot;testing for loops&quot; count = 0 #initialize counter for i in string: if(i == &#39;t&#39;): count += 1 print(count) #How many letters &quot;t&quot;? #&gt; 2 while or for? Usually we‚Äôd use the for loop when the number of iterations is fixed. For example, iterating over a fixed list of items in a shopping list. The while loop is useful in cases when the number of iterations isn‚Äôt known and depends on some calculations and conditions in the code block of the loop. 2.1.5 Functions Functions are defined with the def statement. The statement ends with a colon, and the code that is part of the function is indented below the def statement. def function(x): return(x) function(5) #&gt; 5 2.1.5.1 Functional Programming In this section I will define higher-order functions ##### Pure functions These are functions that have no side effects, and return a value that depend only on the argument and therefore it doesn‚Äôt change the structure of functions or elements within. def pure_function(x,y): temp = x + 2*y return temp / (2*x + y) pure_function(2,1) #&gt; 0.8 easier to test and reasoning more efficient. It reduces the number of times the function is called (memoization) easier to run in parallel 2.1.5.1.1 Lambdas Python allows to create functions on-the-fly (anonymous), thanks to lambda() syntax. However they are not as powerful as takes a single line of code #Named Functions def polynomial(x): return x**2 + 5*x + 4 print(polynomial(1)) #&gt; 10 #Lambda print((lambda x: x**2 + 5*x + 4) (1)) #argument:(1) #&gt; 10 2.1.5.1.2 map and filter These two are high-order functions that operate on lists or iterables. - The function map() takes a function and an iterable as arguments and returns a new iterable with the function applied to each argument def add_five(x): return x+5 nums = list(range(0,11)) result = list(map(add_five,nums)) print(result) #&gt; [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15] The filter() function filters an iterable, leaving only the objects that match a condition (predicate) nums = [11,22,33,44,55] #return even number from the list res = list(filter(lambda x: x%2==0, nums)) print(res) #&gt; [22, 44] 2.1.5.1.3 Generators Generators are a type of iterable. They are created by the yield statement, which replaces the return of a function to provide a result without destroying local variables. Moreover as they yield one item at time, generators don‚Äôt have memory restrictions and so can be infinite. They can be converted into list with the function list(). def countdown(): i=5 while i &gt; 0: yield i i -= 1 print(list(countdown())) #&gt; [5, 4, 3, 2, 1] Its usage results in improved performance, as consume low memory and there is no need to wait until all elements have been generated before starting using them 2.2 Collection Types 2.2.1 Lists At their simplest, Lists are used to store items. We can create a list by using square brackets with commas separating items. Like this: words = [&quot;Hello&quot;, &quot;world&quot;, &quot;!&quot;] print(words[0]) #&gt; Hello print(words[1]) #&gt; world print(words[2]) #or: #&gt; ! print(words[0]+ &quot; &quot; + words[1] + words[2]) #&gt; Hello world! Indexing a string is like creating a list containing each character in the string. string = &quot;Hello world!&quot; print(string[0]) #First element is indexed w/ 0 #&gt; H print(&quot;H&quot; in string) #&gt; True print(&quot;Hello&quot; not in string) #&gt; False Lists can also be added and multiplied in the same way as strings. nums = [1, 2, 3] print(nums + [4, 5, 6]) #&gt; [1, 2, 3, 4, 5, 6] print(nums * 3) #&gt; [1, 2, 3, 1, 2, 3, 1, 2, 3] 2.2.1.1 range() This function, if converted to a list, creates number sequences of the form: \\([a,b) \\ \\ | \\ a \\le x &lt;b\\), i.e. the argument won‚Äôt be included in the list #To produce an object from 0 to first argument print(list(range(10))) #&gt; [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] #To produce an object from 1st to 2nd argument(not included) print(list(range(1,4))) #&gt; [1, 2, 3] A third argument can be added if you want to include steps #From 0 to 10 by step of 2 (even numbers) print(list(range(0,10,2))) #&gt; [0, 2, 4, 6, 8] 2.2.1.2 List Slices Other way to retrieve values from a list: using : numbers = list(range(0,11)) print(numbers[:6]) #numbers from 1st to 5th #&gt; [0, 1, 2, 3, 4, 5] print(numbers[5:]) #from the 5th to last #&gt; [5, 6, 7, 8, 9, 10] #Retrieve elements from list by step of 2 print(numbers[::2]) #&gt; [0, 2, 4, 6, 8, 10] #Retrieve elements from 1st argument to nth last one using - print(numbers[1:-2]) #from 2nd to 3rd last one #&gt; [1, 2, 3, 4, 5, 6, 7, 8] There is a way to remove an item from a list given its index instead of its value: the *del* statement. This differs from the pop() method which returns a value. The del statement can also be used to remove slices from a list or clear the entire list #delete numbers from 2 to 9 in numbers list del numbers[2:10] numbers #&gt; [0, 1, 10] 2.2.1.3 List Comprehensions This is a way to creating lists whose contents obey a rule evens = [i**2 for i in range(10) if i**2 % 2 == 0] print(evens) #&gt; [0, 4, 16, 36, 64] 2.2.1.4 List Functions len(): Gets you the number of items in a list (or a string) .append() Adds an element at the end of the list .clear() Removes all the elements from the list .copy() Returns a copy of the list .count() Returns the number of elements with the specified value .extend() Add the elements of a list (or any iterable), to the end of the current list .index() Returns the index of the first element with the specified value .insert() Adds an element at the specified position .pop() Removes the element at the specified position .remove() Removes the first item with the specified value .reverse() Reverses the order of the list .sort() Sorts the list 2.2.1.5 Strings Function .join- joins a list of strings with another string as a separator. replace- replaces one substring in a string with another. .startswithand .endswith - determine if there is a substring at the start and end of a string, respectively. .lowerand .upper‚Äì changes the case of a string .split - the opposite of .join, turns a string with a certain separator into a list. .find() - Searches the string for a specified value and returns the position of where it was found .format() - Formats specified values in a string .format_map() - Formats specified values in a string .index() - Searches the string for a specified value and returns the position of where it was found .isalpha() - Returns True if all characters in the string are in the alphabet .swapcase() - Swaps cases, lower case becomes upper case and vice versa .title() - Converts the first character of each word to upper case .translate() - Returns a translated string 2.2.2 Matrixes We can use nested lists to represent 2D grids, such as matrices. m = [ [1, 2, 3], [4, 5, 6] ] #The code below outputs the 3rd item of the 2nd row. print(m[1][2]) #&gt; 6 However it‚Äôs mainly used the NumPy (Chapter 3 is a package for scientific computing which has support for a powerful N-dimensional array object. Before you can use NumPy, you need to install it. For more info, 2.2.3 Dictionaries Another useful data type built into Python is the dictionary. Dictionaries are sometimes found in other languages as ‚Äúassociative memories‚Äù or ‚Äúassociative arrays‚Äù. Unlike sequences, which are indexed by a range of numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be keys. prefix = {&#39;italy&#39;: 39, &#39;spain&#39;: 34, &#39;france&#39;: 33} prefix[&#39;italy&#39;] #&gt; 39 The dict() constructor builds dictionaries directly from sequences of key-value pairs dict([(&#39;sape&#39;, 4139), (&#39;guido&#39;, 4127), (&#39;jack&#39;, 4098)]) #&gt; {&#39;sape&#39;: 4139, &#39;guido&#39;: 4127, &#39;jack&#39;: 4098} 2.2.4 Tuples Tuples are immutable sequences, typically used to store collections of heterogeneous data. Tuples may be constructed in a number of ways: Using a pair of parentheses to denote the empty tuple: () Using a trailing comma for a singleton tuple: a, or (a,) Separating items with commas: a, b, c or (a, b, c) Using the tuple() built-in: tuple() or tuple(iterable) 2.2.5 Sets "],["numpy.html", "Chapter 3 Numpy 3.1 Arrays 3.2 Operators", " Chapter 3 Numpy Numpy is the core library for scientific computing in Python. It provides a high-performance multidimensional array object, and tools for working with these arrays 3.1 Arrays A numpy array is a grid of values, all of the same type, and is indexed by a tuple of nonnegative integers. The number of dimensions is the rank of the array. The shape of an array is a tuple of integers giving the size (the total number of elements) of the array along each dimension. import numpy as np # 1-dimensonal array, also referred to as a vector a1 = np.array([1, 2, 3]) a1.shape, a1.ndim, a1.dtype, a1.size, type(a1) #&gt; ((3,), 1, dtype(&#39;int64&#39;), 3, &lt;class &#39;numpy.ndarray&#39;&gt;) # 2-dimensional array, also referred to as matrix a2 = np.array([[1, 2.0, 3.3], [4, 5, 6.5]]) a2.shape, a2.ndim, a2.dtype, a2.size, type(a2) #&gt; ((2, 3), 2, dtype(&#39;float64&#39;), 6, &lt;class &#39;numpy.ndarray&#39;&gt;) # 3-dimensional array, also referred to as a matrix a3 = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[10, 11, 12], [13, 14, 15], [16, 17, 18]]]) a3.shape, a3.ndim, a3.dtype, a3.size, type(a3) #&gt; ((2, 3, 3), 3, dtype(&#39;int64&#39;), 18, &lt;class &#39;numpy.ndarray&#39;&gt;) 3.1.1 Creating Arrays np.array() np.ones() np.full() np.zeros() np.random.rand(5, 3) np.random.randint(10, size=5) np.random.seed() - pseudo random numbers You can change the data type with .astype() or calling the argument dtype= when creating. # Create an array of ones, 10 rows of 2 cols type integer ones = np.ones((10, 2)) # Create an array of zeros zeros = np.zeros((5, 3, 3)) # One-dim array from 1 to 10 a = np.arange(1,11) # One-dim array of 100 numbers from 1 to 10 a = np.linspace(1,11,50) # Random array of integers a = np.random.randint(10, size=(5, 3)) # Random array of floats (between 0 &amp; 1) a = np.random.random((5, 3)) For consistency, you might want to keep the random numbers you generate similar throughout experiments. To do this, you can use np.random.seed(). 3.1.2 Indexing and slicing arrays Array shapes are always listed in the format (row, column, n...) where n is optional extra dimension(s). a = np.arange(100) a = a.reshape(50,2) a[0,1] # same form of an access to a nested list or a[0][1] #&gt; 1 a[1:3] # row slice #&gt; array([[2, 3], #&gt; [4, 5]]) a[:,0] # project on first column #&gt; array([ 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, #&gt; 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, #&gt; 68, 70, 72, 74, 76, 78, 80, 82, 84, 86, 88, 90, 92, 94, 96, 98]) a[0] # first row or a[0, :] #&gt; array([0, 1]) a[:3,0] # Get the first value of the first 3 row #&gt; array([0, 2, 4]) b = np.arange(48).reshape(4, 12) b, b[(0,2), 2:5], b[:, (-1, 2, -1)] # returns a 1D array with b[-1, 5], b[2, 9], b[-1, 1] and b[2, 9] #&gt; (array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], #&gt; [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], #&gt; [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35], #&gt; [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]]), array([[ 2, 3, 4], #&gt; [26, 27, 28]]), array([[11, 2, 11], #&gt; [23, 14, 23], #&gt; [35, 26, 35], #&gt; [47, 38, 47]])) b[(-1, 2, -1, 2), (5, 9, 1, 9)] #&gt; array([41, 33, 37, 33]) 3.1.3 Reshape a = np.arange(0,11) ## Reshape into n rows of n col # Row vector a = a.reshape((1,11)) #a[np.newaxis, :] a #&gt; array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]) # Column vector a = a.reshape((11,1)) #a[:, np.newaxis] a #&gt; array([[ 0], #&gt; [ 1], #&gt; [ 2], #&gt; [ 3], #&gt; [ 4], #&gt; [ 5], #&gt; [ 6], #&gt; [ 7], #&gt; [ 8], #&gt; [ 9], #&gt; [10]]) # Transpose the array a.T #&gt; array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]]) 3.1.3.1 Aggregate #Concatenate (The arrays must have equal numbers of dimensions) a=np.array([1,2,3]) b=np.array([4,5,6]) c=np.array([7,8,9]) np.concatenate([a, b, c]) #&gt; array([1, 2, 3, 4, 5, 6, 7, 8, 9]) For arrays with different numbers of dimensions, use vstack and hstack to perform concatenation. The inverse operation, splitting, is implemented by split,vsplit,hsplit a = np.array([2,3,5]) b = np.array([[7,11,13], [17,19,23]]) np.vstack([a, b]) #np.concatenate((a, b), axis=0) #&gt; array([[ 2, 3, 5], #&gt; [ 7, 11, 13], #&gt; [17, 19, 23]]) b = np.array([[29], [31]]) b2 = np.array([[7,11,13], [17,19,23]]) np.hstack([b, b2]) ##np.concatenate((a, b), axis=1) #&gt; array([[29, 7, 11, 13], #&gt; [31, 17, 19, 23]]) a = np.array([2,3,5,7,11,13,17,19,23]) a1, a2, a3 = np.split(a, [3,6]) a1, a2, a3 #&gt; (array([2, 3, 5]), array([ 7, 11, 13]), array([17, 19, 23])) There is also a split function which splits an array along any given axis. Calling vsplit is equivalent to calling split with axis=0. There is also an hsplit function, equivalent to calling split with axis=1. 3.1.3.2 Sort np.sort() np.argsort() np.argmax() np.argmin() 3.1.3.3 Transpose The transpose method creates a new view on an ndarray‚Äôs data, with axes permuted in the given order. By default, transpose reverses the order of the dimensions: a = np.arange(24).reshape(4,2,3) a #&gt; array([[[ 0, 1, 2], #&gt; [ 3, 4, 5]], #&gt; #&gt; [[ 6, 7, 8], #&gt; [ 9, 10, 11]], #&gt; #&gt; [[12, 13, 14], #&gt; [15, 16, 17]], #&gt; #&gt; [[18, 19, 20], #&gt; [21, 22, 23]]]) a2= a.transpose() # equivalent to t.transpose((2, 1, 0)) Now let‚Äôs create an ndarray such that the axes 0, 1, 2 (depth, height, width) are re-ordered to 1, 2, 0 (depth‚Üíwidth, height‚Üídepth, width‚Üíheight): a1 = a.transpose((1,2,0)) a1, a1.shape #&gt; (array([[[ 0, 6, 12, 18], #&gt; [ 1, 7, 13, 19], #&gt; [ 2, 8, 14, 20]], #&gt; #&gt; [[ 3, 9, 15, 21], #&gt; [ 4, 10, 16, 22], #&gt; [ 5, 11, 17, 23]]]), (2, 3, 4)) NumPy provides a convenience function swapaxes() to swap two axes. For example, let‚Äôs create a new view of t with depth and height swapped: a3 = a.swapaxes(0,1) # equivalent to a.transpose((1, 0, 2)) a3 #&gt; array([[[ 0, 1, 2], #&gt; [ 6, 7, 8], #&gt; [12, 13, 14], #&gt; [18, 19, 20]], #&gt; #&gt; [[ 3, 4, 5], #&gt; [ 9, 10, 11], #&gt; [15, 16, 17], #&gt; [21, 22, 23]]]) The T attribute is equivalent to calling transpose() when the rank is 2. The T attribute has no effect on rank 0 (empty) or rank 1 arrays. a.T #&gt; array([[[ 0, 6, 12, 18], #&gt; [ 3, 9, 15, 21]], #&gt; #&gt; [[ 1, 7, 13, 19], #&gt; [ 4, 10, 16, 22]], #&gt; #&gt; [[ 2, 8, 14, 20], #&gt; [ 5, 11, 17, 23]]]) 3.2 Operators All the usual arithmetic operators can be used with ndarrays. They apply element wise: * Arithmetic * +, -, *, /, //, **, % * np.exp() * np.log() * np.dot() - Dot product The arrays must have the same shape. If they do not, NumPy will apply the broadcasting rules. 3.2.1 Broadcasting Rules If the arrays do not have the same rank, then a 1 will be prepended to the smaller ranking arrays until their ranks match. h = np.arange(5).reshape(1, 1, 5) h #&gt; array([[[0, 1, 2, 3, 4]]]) Now let‚Äôs try to add a 1D array of shape (5,) to this 3D array of shape (1,1,5). Applying the first rule of broadcasting! h + [10, 20, 30, 40, 50] #same as: h + [[[10, 20, 30, 40, 50]]] #&gt; array([[[10, 21, 32, 43, 54]]]) Arrays with a 1, along a particular dimension, act as if they had the size of the array with the largest shape along that dimension. The value of the array element is repeated along that dimension. k = np.arange(6).reshape(2,3) k #&gt; array([[0, 1, 2], #&gt; [3, 4, 5]]) Let‚Äôs try to add a 2D array of shape (2,1) to this 2D ndarray of shape (2, 3). NumPy will apply the second rule of broadcasting: k + [[100], [200]] # same as: k + [[100, 100, 100], [200, 200, 200]] #&gt; array([[100, 101, 102], #&gt; [203, 204, 205]]) Combining rules 1 &amp; 2, we can do this: k + [100, 200, 300] # after rule 1: [[100, 200, 300]], and after rule 2:‚ê£ Ùè∞∞‚Üí[[100, 200, 300], [100, 200, 300]] #&gt; array([[100, 201, 302], #&gt; [103, 204, 305]]) After rules 1 &amp; 2, the sizes of all arrays must match. try: k + [33, 44] except ValueError as e: print(e) #&gt; operands could not be broadcast together with shapes (2,3) (2,) 3.2.2 Upcasting When trying to combine arrays with different dtypes, NumPy will upcast to a type capable of handling all possible values (regardless of what the actual values are). k1 = np.arange(0, 5, dtype=np.uint8) print(k1.dtype, k1) #&gt; uint8 [0 1 2 3 4] k2 = k1 + np.array([5, 6, 7, 8, 9], dtype=np.int8) # Note that int16 is required to represent all possible int8 and uint8 values (from -128 to 255) print(k2.dtype, k2) #&gt; int16 [ 5 7 9 11 13] k3 = k1 + 1.5 print(k3.dtype, k3) #&gt; float64 [1.5 2.5 3.5 4.5 5.5] 3.2.3 Conditional operators The conditional operators also apply elementwise. Comparison operators &gt; &lt; &lt;= &gt;= x != 3 x == 3 np.sum(x &gt; 3) k2 &lt; np.array([2, 8, 11, 9, 6]) #&gt; array([False, True, True, False, False]) k2 &lt; 8 #&gt; array([ True, True, False, False, False]) 3.2.4 Statistics Many mathematical and statistical functions are available for ndarrays. Aggregation np.sum() - faster than .sum() np.prod() np.mean() np.std() np.var() np.min() np.max() np.argmin() - find index of minimum value np.argmax() - find index of maximum value These functions accept an optional argument axis which lets you ask for the operation to be performed on elements along the given axis. For example: c=np.arange(24).reshape(2,3,4) c #&gt; array([[[ 0, 1, 2, 3], #&gt; [ 4, 5, 6, 7], #&gt; [ 8, 9, 10, 11]], #&gt; #&gt; [[12, 13, 14, 15], #&gt; [16, 17, 18, 19], #&gt; [20, 21, 22, 23]]]) c.sum(axis=0) # sum across matrices #&gt; array([[12, 14, 16, 18], #&gt; [20, 22, 24, 26], #&gt; [28, 30, 32, 34]]) c.sum(axis=1) # sum across rows #&gt; array([[12, 15, 18, 21], #&gt; [48, 51, 54, 57]]) c.sum(axis=(0,2)) # sum across matrices and columns (first row, second row , 8+9+10+11 + 20+21+22+23) #&gt; array([ 60, 92, 124]) 3.2.5 Linear Algebra Linear algebra functions are available in the numpy.linalg module. The inv function computes a square matrix‚Äôs inverse, whereas the pinv() computes the pseudoinverse. import numpy.linalg as linalg a = np.array([[1,2,3],[5,7,11],[21,29,31]]) linalg.inv(a), linalg.pinv(a) #&gt; (array([[-2.31818182, 0.56818182, 0.02272727], #&gt; [ 1.72727273, -0.72727273, 0.09090909], #&gt; [-0.04545455, 0.29545455, -0.06818182]]), array([[-2.31818182, 0.56818182, 0.02272727], #&gt; [ 1.72727273, -0.72727273, 0.09090909], #&gt; [-0.04545455, 0.29545455, -0.06818182]])) The qr function computes the QR decomposition of a matrix, also known as a QR factorization or QU factorization. It is a decomposition of a matrix A into a product A = QR of an orthogonal matrix Q and an upper triangular matrix R. q, r = linalg.qr(a) #q.dot(r) -&gt; q**r equals a The det() function computes the matrix determinant. linalg.det(a) #&gt; 43.99999999999997 The eig() function from linalg computes the eigenvalues and eigenvectors of a square matrix: eigenvalues, eigenvectors = linalg.eig(a) eigenvalues, eigenvectors #&gt; (array([42.26600592, -0.35798416, -2.90802176]), array([[-0.08381182, -0.76283526, -0.18913107], #&gt; [-0.3075286 , 0.64133975, -0.6853186 ], #&gt; [-0.94784057, -0.08225377, 0.70325518]])) The diag() function returns the elements on the diagonal, whereas trace() returns their sum: np.diag(a),np.trace(a) #&gt; (array([ 1, 7, 31]), 39) The solve function solves a system of linear scalar equations, such as: \\[2x+6y=6\\] \\[5x+3y=-9\\] coeffs = np.array([[2, 6], [5, 3]]) depvars = np.array([6, -9]) solution = linalg.solve(coeffs, depvars) solution #&gt; array([-3., 2.]) "],["pandas.html", "Chapter 4 Pandas 4.1 Series 4.2 DataFrame", " Chapter 4 Pandas A powerful library for data manipulation and analysis, borrowing the idea of data frames from the R language. An essential import setup for Pandas is import pandas as pd from datetime import datetime, date 4.1 Series Similar to one-dimensional NumPy array, with the addition of an index which can comprisearbitrary values pd.Series([2,5,6,7]) #&gt; 0 2 #&gt; 1 5 #&gt; 2 6 #&gt; 3 7 #&gt; dtype: int64 In the example above, the index has not been specified, and it defaults to the standard 0-based integer index. s = pd.Series([2,5,6,7],index=(&quot;prime1&quot;,&quot;prime2&quot;,&quot;prime3&quot;,&quot;prime4&quot;)) print(s) #&gt; prime1 2 #&gt; prime2 5 #&gt; prime3 6 #&gt; prime4 7 #&gt; dtype: int64 And then indexes can be used for slicing s[[&quot;prime2&quot;,&quot;prime4&quot;]] #&gt; prime2 5 #&gt; prime4 7 #&gt; dtype: int64 When instantiated from a dictionary input, the keys are used to create the index s = pd.Series({&#39;Friday&#39;:0.2,&#39;Saturday&#39;:1.0,&#39;Sunday&#39;:4.2,&#39;Monday&#39;:0.0,&#39;Tuesday&#39;:1.2}) print(s[1:3]) #&gt; Saturday 1.0 #&gt; Sunday 4.2 #&gt; dtype: float64 The overall behaviour of Series is similar to that of ndarray, as far as slicing and indexing are concerned: def fahrenheit(t): return 9*t/5+32 s[s&lt;1.2], #&gt; (Friday 0.2 #&gt; Saturday 1.0 #&gt; Monday 0.0 #&gt; dtype: float64,) fahrenheit(s) #&gt; Friday 32.36 #&gt; Saturday 33.80 #&gt; Sunday 39.56 #&gt; Monday 32.00 #&gt; Tuesday 34.16 #&gt; dtype: float64 Series has some features of dict, like assignment by index and testing of index value membership s[&#39;Monday&#39;] = np.nan pd.isna(s[&#39;Monday&#39;]) #&gt; True dt=pd.date_range(&#39;2019-10-29&#39;,&#39;2019-11-02&#39;) print(dt) #&gt; DatetimeIndex([&#39;2019-10-29&#39;, &#39;2019-10-30&#39;, &#39;2019-10-31&#39;, &#39;2019-11-01&#39;, #&gt; &#39;2019-11-02&#39;], #&gt; dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) precip_sp = pd.Series([0.2,1.0,4.2,0.0,1.2],index=dt) print(precip_sp) #&gt; 2019-10-29 0.2 #&gt; 2019-10-30 1.0 #&gt; 2019-10-31 4.2 #&gt; 2019-11-01 0.0 #&gt; 2019-11-02 1.2 #&gt; Freq: D, dtype: float64 precip_bu = pd.Series([0.0,0.0,0.0,1.2,4.2,0.0], index=pd.date_range(&#39;2019-10-27&#39;,&#39;2019-11-01&#39;)) #NaN as precip_bu and precip_sp have different indexes range print(precip_sp-precip_bu) #&gt; 2019-10-27 NaN #&gt; 2019-10-28 NaN #&gt; 2019-10-29 0.2 #&gt; 2019-10-30 -0.2 #&gt; 2019-10-31 0.0 #&gt; 2019-11-01 0.0 #&gt; 2019-11-02 NaN #&gt; Freq: D, dtype: float64 4.2 DataFrame A2-dimensional, table-like, data structure with columns of possibly different types and an index for its rows. You can create a DataFrame by passing a dictionary of Series objects: people_dict = { &quot;weight&quot;: pd.Series([68, 83, 112], index=[&quot;alice&quot;, &quot;martino&quot;, &quot;franco&quot;]), &quot;birthyear&quot;: pd.Series([1984, 1985, 1992], index=[&quot;alice&quot;, &quot;martino&quot;,&quot;franco&quot;], name=&quot;year&quot;), &quot;children&quot;: pd.Series([0, 3], index=[&quot;martino&quot;, &quot;franco&quot;]), &quot;hobby&quot;: pd.Series([&quot;Biking&quot;, &quot;Dancing&quot;], index=[&quot;alice&quot;, &quot;martino&quot;]), } people = pd.DataFrame(people_dict) people #&gt; weight birthyear children hobby #&gt; alice 68 1984 NaN Biking #&gt; franco 112 1992 3.0 NaN #&gt; martino 83 1985 0.0 Dancing Another convenient way to create a DataFrame is to pass all the values to the constructor as an ndarray, or a list of lists, and specify the column names and row index labels separately: values = [ [1985, np.nan, &quot;Biking&quot;, 68], [1984, 3, &quot;Dancing&quot;, 83], [1992, 0, np.nan, 112] ] d = pd.DataFrame( values, columns=[&quot;birthyear&quot;, &quot;children&quot;, &quot;hobby&quot;, &quot;weight&quot;], index=[&quot;alice&quot;, &quot;martino&quot;, &quot;franco&quot;]) d #&gt; birthyear children hobby weight #&gt; alice 1985 NaN Biking 68 #&gt; martino 1984 3.0 Dancing 83 #&gt; franco 1992 0.0 NaN 112 precips = pd.DataFrame({&#39;San Pietro Capofiume&#39;: precip_sp,&#39;Bologna Urbana&#39;: precip_bu}) print(precips) #&gt; San Pietro Capofiume Bologna Urbana #&gt; 2019-10-27 NaN 0.0 #&gt; 2019-10-28 NaN 0.0 #&gt; 2019-10-29 0.2 0.0 #&gt; 2019-10-30 1.0 1.2 #&gt; 2019-10-31 4.2 4.2 #&gt; 2019-11-01 0.0 0.0 #&gt; 2019-11-02 1.2 NaN Panda‚Äôs DataFrame() function is flexible as to the types of its inputs. As a list of dictionaries, each dictionary element of the input list is one row ofthe data frame city_loc = pd.DataFrame([{&#39;Lat&#39;:44.49381,&#39;Long&#39;:11.33875}, {&#39;Lat&#39;:41.89193,&#39;Long&#39;:12.51133}], index=[&#39;Bologna&#39;,&#39;Rome&#39;]) print(city_loc) #&gt; Lat Long #&gt; Bologna 44.49381 11.33875 #&gt; Rome 41.89193 12.51133 DataFrame behaves like a dictionary, in which keys are column names and the values are index-aligned Series city_loc[&#39;Lat&#39;] #&gt; Bologna 44.49381 #&gt; Rome 41.89193 #&gt; Name: Lat, dtype: float64 # add an elevation column for example as a list city_loc[&#39;Elev&#39;] = [54,21] city_loc #&gt; Lat Long Elev #&gt; Bologna 44.49381 11.33875 54 #&gt; Rome 41.89193 12.51133 21 4.2.1 Indexing 4.2.1.1 .loc[] attribute Label-based indexing is supported via the attribute .loc[], the result is a Series object. precips.loc[&#39;2019-10-30&#39;], #&gt; (San Pietro Capofiume 1.0 #&gt; Bologna Urbana 1.2 #&gt; Name: 2019-10-30 00:00:00, dtype: float64,) type(precips.loc[&#39;2019-10-30&#39;]) #&gt; &lt;class &#39;pandas.core.series.Series&#39;&gt; .loc[] supports slicing. However, unlike ndarray integer-based slicing,it includes the upper label: precips.loc[&#39;2019-10-29&#39;:&#39;2019-11-01&#39;] #&gt; San Pietro Capofiume Bologna Urbana #&gt; 2019-10-29 0.2 0.0 #&gt; 2019-10-30 1.0 1.2 #&gt; 2019-10-31 4.2 4.2 #&gt; 2019-11-01 0.0 0.0 and it also allows for list of labels: # Note: in this example the list has to be transformed into a DatetimeIndex because the Series objects which were the input of the data frame had been constructed with a DatetimeIndex precips.loc[pd.DatetimeIndex([&#39;2019-10-31&#39;,&#39;2019-11-01&#39;,&#39;2019-11-02&#39;])] #&gt; San Pietro Capofiume Bologna Urbana #&gt; 2019-10-31 4.2 4.2 #&gt; 2019-11-01 0.0 0.0 #&gt; 2019-11-02 1.2 NaN Is it possible to index through booleans #create index with missing values na=(pd.isna(precips[&#39;Bologna Urbana&#39;])|pd.isna(precips[&#39;San Pietro Capofiume&#39;])) #index full dataset without(-) values which are na precips.loc[~na] #&gt; San Pietro Capofiume Bologna Urbana #&gt; 2019-10-29 0.2 0.0 #&gt; 2019-10-30 1.0 1.2 #&gt; 2019-10-31 4.2 4.2 #&gt; 2019-11-01 0.0 0.0 4.2.1.2 .iloc[] attribute The.iloc attribute provides integer-based indexing, following the usual Pythonconventions. The allowed types of input are the same as.loc, but integers mustbe specified instead of labels. The following examples return the same resultsas the ones above: precips.iloc[3] #&gt; San Pietro Capofiume 1.0 #&gt; Bologna Urbana 1.2 #&gt; Name: 2019-10-30 00:00:00, dtype: float64 precips.iloc[2:6] #&gt; San Pietro Capofiume Bologna Urbana #&gt; 2019-10-29 0.2 0.0 #&gt; 2019-10-30 1.0 1.2 #&gt; 2019-10-31 4.2 4.2 #&gt; 2019-11-01 0.0 0.0 precips.iloc[[4,5,6]] #&gt; San Pietro Capofiume Bologna Urbana #&gt; 2019-10-31 4.2 4.2 #&gt; 2019-11-01 0.0 0.0 #&gt; 2019-11-02 1.2 NaN Is it possible to index with booleans, however first we need to convert it to a numpy array wiht .to_numpy() precips.iloc[~na.to_numpy()] #&gt; San Pietro Capofiume Bologna Urbana #&gt; 2019-10-29 0.2 0.0 #&gt; 2019-10-30 1.0 1.2 #&gt; 2019-10-31 4.2 4.2 #&gt; 2019-11-01 0.0 0.0 The .query() method lets you filter a DataFrame based on a query expression: 4.2.2 Reading Data 4.2.2.1 read_csv # iris1 = pd.read_csv(&quot;https://raw.githubusercontent.com/SakshamAyush/Iris_Flower_Classification/master/data/bezdekIris.csv&quot;) The compression argument enables to specify the decompression algorithm if dataset is a compressed CSV file, setting the value 'infer' chooses it by file extension. By default, time series are not recognized, the dtypeof the series is object, it should be datetime64[ns]. the parse_dates argument enables us to specify a list of columns that must be parse as dates (i.e. parse_dates = ['year'] or parse_dates = [0]) The index_col argument enables us to set a sequence of columns as row labels (ex. index_col='Time') 4.2.2.2 read_excel The read_excel function enables the reading of .xls and .xlsx files. Installation of either xlrd or openpyxl (for Excel 2007,.xlsx) is a prerequisite. 4.2.3 Data Wrangling Function pd.concat on a list of objects can concatenate Series or DataFrame objects #Row labels are not modified s1=pd.Series([1,2,3]) s2=pd.Series([4,5,6]) s=pd.concat([s1, s2]) s #&gt; 0 1 #&gt; 1 2 #&gt; 2 3 #&gt; 0 4 #&gt; 1 5 #&gt; 2 6 #&gt; dtype: int64 Be careful when concatenating DataFrame objects. Let c1 and c2 be the column labels of the 1st and 2nd frame Columnsùê∂2 and ùê∂1 are added to first data frame, columnsùê∂1 and ùê∂2 to the second, all filled with NaN. The rows of the second frame are appended to the first df1=pd.DataFrame({&#39;a&#39;: [1,2,3],&#39;b&#39;: [4,5,6]}) df2=pd.DataFrame({&#39;b&#39;: [7,8,9],&#39;c&#39;: [10,11,12]}) df=pd.concat([df1, df2]) 4.2.3.1 Multi-indexing If all columns are tuples of the same size, then they are understood as a multi-index. The same goes for row index labels. For example: d = pd.DataFrame( { (&quot;public&quot;, &quot;birthyear&quot;): {(&quot;Paris&quot;,&quot;alice&quot;):1985, (&quot;Paris&quot;,&quot;martino&quot;): 1984, (&quot;London&quot;,&quot;franco&quot;):1992}, (&quot;public&quot;, &quot;hobby&quot;): {(&quot;Paris&quot;,&quot;alice&quot;):&quot;Biking&quot;, (&quot;Paris&quot;,&quot;martino&quot;): &quot;Dancing&quot;}, (&quot;private&quot;, &quot;weight&quot;): {(&quot;Paris&quot;,&quot;alice&quot;):68, (&quot;Paris&quot;,&quot;martino&quot;): 83, (&quot;London&quot;,&quot;franco&quot;): 112}, (&quot;private&quot;, &quot;children&quot;): {(&quot;Paris&quot;, &quot;alice&quot;):np.nan, (&quot;Paris&quot;,&quot;martino&quot;): 3, (&quot;London&quot;,&quot;franco&quot;): 0} } ) d #&gt; public private #&gt; birthyear hobby weight children #&gt; Paris alice 1985 Biking 68 NaN #&gt; martino 1984 Dancing 83 3.0 #&gt; London franco 1992 NaN 112 0.0 You can transpose columns and indices using the .T attribute: dT = d.T There are two levels of columns, and two levels of indices. We can drop a column level by calling droplevel() (the same goes for indices): dT.columns = dT.columns.droplevel(level = 0) dT #&gt; alice martino franco #&gt; public birthyear 1985 1984 1992 #&gt; hobby Biking Dancing NaN #&gt; private weight 68 83 112 #&gt; children NaN 3.0 0.0 4.2.3.2 Stacking and unstacking levels Calling the stack() method will push the lowest column level after the lowest index: d.stack() #&gt; private public #&gt; Paris alice birthyear NaN 1985 #&gt; hobby NaN Biking #&gt; weight 68.0 NaN #&gt; martino birthyear NaN 1984 #&gt; children 3.0 NaN #&gt; hobby NaN Dancing #&gt; weight 83.0 NaN #&gt; London franco birthyear NaN 1992 #&gt; children 0.0 NaN #&gt; weight 112.0 NaN dT.stack() #&gt; public birthyear alice 1985 #&gt; martino 1984 #&gt; franco 1992 #&gt; hobby alice Biking #&gt; martino Dancing #&gt; private weight alice 68 #&gt; martino 83 #&gt; franco 112 #&gt; children martino 3.0 #&gt; franco 0.0 #&gt; dtype: object Note that many NaN values appeared. This makes sense because many new combinations did not exist before (eg. there was no bob in London). Calling unstack() will do the reverse, once again creating many NaN values. dT.unstack() #&gt; alice ... franco #&gt; birthyear children hobby weight ... birthyear children hobby weight #&gt; private NaN NaN NaN 68 ... NaN 0.0 NaN 112 #&gt; public 1985 NaN Biking NaN ... 1992 NaN NaN NaN #&gt; #&gt; [2 rows x 12 columns] The stack() and unstack() methods let you select the level to stack/unstack. You can even stack/unstack multiple levels at once, specifying the level parameter. 4.2.3.3 Adding or removing columns people #&gt; weight birthyear children hobby #&gt; alice 68 1984 NaN Biking #&gt; franco 112 1992 3.0 NaN #&gt; martino 83 1985 0.0 Dancing people[&quot;age&quot;] = 2018 - people[&quot;birthyear&quot;] # adds a new column &quot;age&quot; people[&quot;over 30&quot;] = people[&quot;age&quot;] &gt; 30 # adds another column &quot;over 30&quot; birthyears = people.pop(&quot;birthyear&quot;) del people[&quot;children&quot;] people #&gt; weight hobby age over 30 #&gt; alice 68 Biking 34 True #&gt; franco 112 NaN 26 False #&gt; martino 83 Dancing 33 True When you add a new column, it must have the same number of rows. Missing rows are filled with NaN, and extra rows are ignored. When adding a new column, it is added at the end (on the right) by default. You can also insert a column anywhere else using the .insert() method. people.insert(1, &quot;height&quot;, [172, 181, 185]) (people .assign(body_mass_index = lambda df: df[&quot;weight&quot;] / (df[&quot;height&quot;] / 100)** 2) .assign(overweight = lambda df: df[&quot;body_mass_index&quot;] &gt; 25) ) #&gt; weight height hobby age over 30 body_mass_index overweight #&gt; alice 68 172 Biking 34 True 22.985398 False #&gt; franco 112 181 NaN 26 False 34.186991 True #&gt; martino 83 185 Dancing 33 True 24.251278 False 4.2.3.4 Sorting a DataFrame You can sort a DataFrame by calling its sort_index method. By default it sorts the rows by their index label, in ascending order, but let‚Äôs reverse the order: people.sort_index(ascending=False) #&gt; weight height hobby age over 30 #&gt; martino 83 185 Dancing 33 True #&gt; franco 112 181 NaN 26 False #&gt; alice 68 172 Biking 34 True Note that sort_index returned a sorted copy of the DataFrame. To modify people directly, we can set the inplace= argument to True. Also, we can sort the columns instead of the rows by setting axis=1 or by the values instead of the labels, we can use sort_values() and specify the column to sort by: people.sort_values(by=&quot;age&quot;, inplace=True) people #&gt; weight height hobby age over 30 #&gt; franco 112 181 NaN 26 False #&gt; martino 83 185 Dancing 33 True #&gt; alice 68 172 Biking 34 True 4.2.3.5 Aggregating Similar to the SQL language, pandas allows grouping your data into groups to run calculations over each group. * .groupby(\" \") Pandas supports spreadsheet-like pivot tables that allow quick data summarization. To illustrate this, let‚Äôs create a simple DataFrame: 4.2.4 Evaluating an expression A great feature supported by pandas is expression evaluation. This relies on the numexpr library which must be installed. people.eval(&quot;weight / (height/100) ** 2 &gt; 25&quot;) #&gt; franco True #&gt; martino False #&gt; alice False #&gt; dtype: bool Assignment expressions are also supported. Let‚Äôs set inplace=True to directly modify the DataFrame rather than getting a modified copy: people.eval(&quot;body_mass_index = weight / (height/100) ** 2&quot;, inplace=True) people #&gt; weight height hobby age over 30 body_mass_index #&gt; franco 112 181 NaN 26 False 34.186991 #&gt; martino 83 185 Dancing 33 True 24.251278 #&gt; alice 68 172 Biking 34 True 22.985398 4.2.5 Handling Missing Data Dealing with missing data is a frequent task when working with real life data. Pandas offers a few tools to handle missing data. grades_array = np.array([[8,8,9],[10,9,9],[4, 8, 2], [9, 10, 10]]) grades = pd.DataFrame(grades_array, columns=[&quot;sep&quot;, &quot;oct&quot;, &quot;nov&quot;], index=[&quot;alice&quot;,&quot;bob&quot;,&quot;charles&quot;,&quot;darwin&quot;]) grades #&gt; sep oct nov #&gt; alice 8 8 9 #&gt; bob 10 9 9 #&gt; charles 4 8 2 #&gt; darwin 9 10 10 bonus_array = np.array([[0,np.nan,2],[np.nan,1,0],[0, 1, 0], [3, 3, 0]]) bonus_points = pd.DataFrame(bonus_array, columns=[&quot;oct&quot;, &quot;nov&quot;, &quot;dec&quot;], index=[&quot;bob&quot;,&quot;colin&quot;, &quot;darwin&quot;, &quot;charles&quot;]) bonus_points #&gt; oct nov dec #&gt; bob 0.0 NaN 2.0 #&gt; colin NaN 1.0 0.0 #&gt; darwin 0.0 1.0 0.0 #&gt; charles 3.0 3.0 0.0 grades + bonus_points #&gt; dec nov oct sep #&gt; alice NaN NaN NaN NaN #&gt; bob NaN NaN 9.0 NaN #&gt; charles NaN 5.0 11.0 NaN #&gt; colin NaN NaN NaN NaN #&gt; darwin NaN 11.0 10.0 NaN Looks like the addition worked in some cases but way too many elements are now empty. That‚Äôs because when aligning the DataFrames, some columns and rows were only present on one side, and thus they were considered missing on the other side (NaN). Then adding NaN to a number results in NaN, hence the result. 4.2.5.1 .fillna() Let‚Äôs try to fix the problem above. For example, we can decide that missing data should result in a zero, instead of NaN. We can replace all NaN values by a any value using the fillna() method: (grades + bonus_points).fillna(0) #fill with 0s #&gt; dec nov oct sep #&gt; alice 0.0 0.0 0.0 0.0 #&gt; bob 0.0 0.0 9.0 0.0 #&gt; charles 0.0 5.0 11.0 0.0 #&gt; colin 0.0 0.0 0.0 0.0 #&gt; darwin 0.0 11.0 10.0 0.0 It‚Äôs a bit unfair that we‚Äôre setting grades to zero in September, though. Perhaps we should decide that missing grades are missing grades, but missing bonus points should be replaced by zeros: better_bonus_points = bonus_points.copy() better_bonus_points.insert(0, &quot;sep&quot;, 0) better_bonus_points.loc[&quot;alice&quot;] = 0 better_bonus_points = better_bonus_points.interpolate(axis=1) final_grades = grades + better_bonus_points final_grades #&gt; dec nov oct sep #&gt; alice NaN 9.0 8.0 8.0 #&gt; bob NaN 10.0 9.0 10.0 #&gt; charles NaN 5.0 11.0 4.0 #&gt; colin NaN NaN NaN NaN #&gt; darwin NaN 11.0 10.0 9.0 4.2.5.2 .dropna() So let‚Äôs call the .dropna() method to get rid of rows that are full of NaNs: final_grades_clean = final_grades.dropna(how=&quot;all&quot;) final_grades_clean #&gt; dec nov oct sep #&gt; alice NaN 9.0 8.0 8.0 #&gt; bob NaN 10.0 9.0 10.0 #&gt; charles NaN 5.0 11.0 4.0 #&gt; darwin NaN 11.0 10.0 9.0 To remove columns that are full of NaNs, we set the axis argument to 1: final_grades_clean = final_grades_clean.dropna(axis=1, how=&quot;all&quot;) final_grades_clean #&gt; nov oct sep #&gt; alice 9.0 8.0 8.0 #&gt; bob 10.0 9.0 10.0 #&gt; charles 5.0 11.0 4.0 #&gt; darwin 11.0 10.0 9.0 4.2.6 Overview Functions The .info() method prints out a summary of each columns contents: the .describe() method gives a nice overview of the main aggregated values over each column: * count: number of non-null (not NaN) values * mean: mean of non-null values * std: standard deviation of non-null values * min: minimum of non-null values * 25%, 50%, 75%: 25th, 50th and 75th percentile of non-null values * max: maximum of non-null values "],["data-visualization.html", "Chapter 5 Data Visualization 5.1 Matplotlib 5.2 Seaborn 5.3 Bokeh 5.4 Plotly", " Chapter 5 Data Visualization 5.1 Matplotlib import matplotlib.pyplot as plt 5.2 Seaborn 5.3 Bokeh 5.4 Plotly "],["clustering.html", "Chapter 6 Clustering", " Chapter 6 Clustering Grouping objects into classes, or classification, is a basic cognitive ability and a fundamental scientific methodology and procedure. The definitions had different historical perspectives: + - Hastie et al. (2001): objects in a cluster ‚Äúare more closely related to oneanother than objects assigned to different clusters.‚Äù Han &amp; Kamber (2006): ‚ÄúA cluster is a collection of data objects that aresimilar to one another within the same cluster and are dissimilar to theobjects in other clusters.‚Äù 6.0.1 Clustering The clustering problem: given a data set, divide it into groups such that the homogeneity of each group is maximized or the separation between groups is maximized, or both are maximized. Homogeneity and separation can be formalized in different ways: Similarity or dissimilarity measure A domain-dependent real function of object pairs measuring their similarity or dissimilarity is assumed Similar objects are homogeneous, dissimilar ones are separated Density estimation A statistical estimate of the probability density function that generated the data is computed Homogeneity is high in regions where the estimated p.d.f. is large Frequency and expectation The number of objects in space volumes Homogeneity is high in the collection of space volumes where the number exceeds its expectation 6.0.2 Type of Clustering Models Clustering models can be categorized according to nesting and coverageproperties: Hierarchical or flat Hierarchical: Clusters may be subdivided into smaller, contained sub-clusters, forming a hierarchy. Exclusive, overlapping or fuzzy Exclusive: Any object is an element of exactly one cluster. Overlapping: Any object may be an element of more than one cluster. Fuzzy: For each cluster, a membership function on objects onto [0,1] is defined. Complete or partial Complete: Any object is an element of some cluster Partial: An object may belong to no cluster; objects not belonging to any cluster can be deemed as noise or outliers. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
